{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moviereview_v2.csv was cleaned in hw 1\n",
    "\n",
    "file = open('deception_data_converted_final_v2.csv', 'w')\n",
    "\n",
    "with open('deception_data_converted_final.csv') as csvfile:\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter = ',')\n",
    "    file.write(','.join(next(reader)) +'\\n') # header\n",
    "    for row in reader:\n",
    "        \n",
    "        file.write(row[0] + ',' + row[1] + ',' + re.sub('\\W+',' ', ''.join(row[2:])) +'\\n') #data stripped and formatted\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 3)\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'deception_data_converted_final_v2.csv'\n",
    "\n",
    "df_review = pd.read_csv(csv_file, encoding = \"ISO-8859-1\")\n",
    "df_review.dropna(inplace=True)\n",
    "print(df_review.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lie</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>Mike s Pizza High Point NY Service was very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>i really like this buffet restaurant in Marsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>After I went shopping with some of my friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>Olive Oil Garden was very disappointing I exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>The Seven Heaven restaurant was never known f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lie sentiment                                             review\n",
       "0   f         n   Mike s Pizza High Point NY Service was very s...\n",
       "1   f         n   i really like this buffet restaurant in Marsh...\n",
       "2   f         n   After I went shopping with some of my friend ...\n",
       "3   f         n   Olive Oil Garden was very disappointing I exp...\n",
       "4   f         n   The Seven Heaven restaurant was never known f..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mike s Pizza High Point NY Service was very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i really like this buffet restaurant in Marsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After I went shopping with some of my friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olive Oil Garden was very disappointing I exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Seven Heaven restaurant was never known f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0   Mike s Pizza High Point NY Service was very s...\n",
       "1   i really like this buffet restaurant in Marsh...\n",
       "2   After I went shopping with some of my friend ...\n",
       "3   Olive Oil Garden was very disappointing I exp...\n",
       "4   The Seven Heaven restaurant was never known f..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lieCol = df_review['lie']\n",
    "sentCol = df_review['sentiment']\n",
    "df_review.drop(['lie','sentiment'], axis=1, inplace=True)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "my_list = [shortword.sub('', df_review.iloc[i,0]) for i in range(len(df_review))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yesterday went casino restaurant called NoFreeDrinks First thought just name later blackjack table when ordered attendant round Jack Coke instead saying Yeah sure attendant said preposterous have never paid drinks casino Clearly casino does understand that more people drink more they will loose Someone needs teach casino business '"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(input=\"content\", analyzer = 'word', stop_words = 'english', lowercase = True)\n",
    "cv = count_vec.fit_transform(my_list)\n",
    "\n",
    "# stolen from Dr. Gates\n",
    "MyColumnNames=count_vec.get_feature_names()\n",
    "VectorizedDF_Text=pd.DataFrame(cv.toarray(),columns=MyColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 1159)\n",
      "(92, 1159)\n"
     ]
    }
   ],
   "source": [
    "print(VectorizedDF_Text.shape) # check size of vecorization before\n",
    "\n",
    "threshold = 0 # threshold for drop\n",
    "to_drop = [] # store indexes needed to be dropped\n",
    "\n",
    "# id all indexes that don't meet threshold       \n",
    "to_drop =  [i for i in range (len(VectorizedDF_Text.columns)) if sum(VectorizedDF_Text.iloc[:,i]) < threshold]  \n",
    "\n",
    "# drop columns that don't meet threshold\n",
    "VectorizedDF_Text.drop(VectorizedDF_Text.columns[to_drop],axis=1,inplace=True)\n",
    "\n",
    "print(VectorizedDF_Text.shape)  # check size of vecorization after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>additional</th>\n",
       "      <th>adorable</th>\n",
       "      <th>affordable</th>\n",
       "      <th>...</th>\n",
       "      <th>wreck</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abruptly  absolutely  acceptable  accord  acknowledge  actual  actually  \\\n",
       "0         0           0           0       0            0       0         0   \n",
       "1         0           0           0       0            0       0         0   \n",
       "2         0           0           0       0            0       0         0   \n",
       "3         0           0           0       0            0       0         0   \n",
       "4         0           0           0       0            0       0         0   \n",
       "\n",
       "   additional  adorable  affordable  ...  wreck  write  written  wrong  wrote  \\\n",
       "0           0         0           0  ...      0      0        0      0      0   \n",
       "1           0         0           0  ...      0      0        0      0      0   \n",
       "2           0         0           0  ...      0      0        0      0      0   \n",
       "3           0         0           0  ...      0      0        0      0      0   \n",
       "4           0         0           0  ...      0      0        0      0      0   \n",
       "\n",
       "   yeah  yelp  yesterday  york  yuenan  \n",
       "0     0     0          0     0       0  \n",
       "1     0     0          0     0       0  \n",
       "2     0     0          0     0       0  \n",
       "3     0     0          0     0       0  \n",
       "4     0     0          0     0       0  \n",
       "\n",
       "[5 rows x 1159 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VectorizedDF_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lie</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accord</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>wreck</th>\n",
       "      <th>write</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuenan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lie Sentiment  abruptly  absolutely  acceptable  accord  acknowledge  \\\n",
       "0   f         n       0.0         0.0         0.0     0.0          0.0   \n",
       "1   f         n       0.0         0.0         0.0     0.0          0.0   \n",
       "2   f         n       0.0         0.0         0.0     0.0          0.0   \n",
       "3   f         n       0.0         0.0         0.0     0.0          0.0   \n",
       "4   f         n       0.0         0.0         0.0     0.0          0.0   \n",
       "\n",
       "   actual  actually  additional  ...  wreck  write  written  wrong  wrote  \\\n",
       "0     0.0       0.0         0.0  ...    0.0    0.0      0.0    0.0    0.0   \n",
       "1     0.0       0.0         0.0  ...    0.0    0.0      0.0    0.0    0.0   \n",
       "2     0.0       0.0         0.0  ...    0.0    0.0      0.0    0.0    0.0   \n",
       "3     0.0       0.0         0.0  ...    0.0    0.0      0.0    0.0    0.0   \n",
       "4     0.0       0.0         0.0  ...    0.0    0.0      0.0    0.0    0.0   \n",
       "\n",
       "   yeah  yelp  yesterday  york  yuenan  \n",
       "0   0.0   0.0        0.0   0.0     0.0  \n",
       "1   0.0   0.0        0.0   0.0     0.0  \n",
       "2   0.0   0.0        0.0   0.0     0.0  \n",
       "3   0.0   0.0        0.0   0.0     0.0  \n",
       "4   0.0   0.0        0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 1161 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vector_df = VectorizedDF_Text.iloc[:,0:].apply(lambda x : x/len(VectorizedDF_Text)) # frequency of words\n",
    "\n",
    "final_vector_df.insert(0, 'Lie', lieCol.to_frame())\n",
    "final_vector_df.insert(1, 'Sentiment', sentCol.to_frame())\n",
    "\n",
    "final_vector_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1161)\n",
      "(28, 1161)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(final_vector_df, test_size=0.3)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.insert(2, 'SL', train_df[['Sentiment', 'Lie']].apply(lambda x: ''.join(x), axis=1))\n",
    "test_df.insert(2, 'SL', test_df[['Sentiment', 'Lie']].apply(lambda x: ''.join(x), axis=1))\n",
    "\n",
    "\n",
    "nb_model_s = MultinomialNB()\n",
    "nb_model_l = MultinomialNB()\n",
    "nb_model_ls = MultinomialNB()\n",
    "sentiment_l = train_df['Sentiment']\n",
    "lie_l = train_df['Lie']\n",
    "lieSent = train_df['SL']\n",
    "\n",
    "\n",
    "train_NB = train_df.drop(['Lie','Sentiment','SL'],axis=1)\n",
    "\n",
    "nb_model_s.fit(train_NB, sentiment_l)\n",
    "nb_model_l.fit(train_NB, lie_l)\n",
    "nb_model_ls.fit(train_NB, lieSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_l = test_df['Lie']\n",
    "actual_s = test_df['Sentiment']\n",
    "actual_ls = test_df['SL']\n",
    "test_NB = test_df.drop(['Lie','Sentiment','SL'],axis=1)\n",
    "\n",
    "prediction_s = nb_model_s.predict(test_NB)\n",
    "prediction_l = nb_model_l.predict(test_NB)\n",
    "prediction_ls = nb_model_ls.predict(test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't' 't'\n",
      " 't' 't' 't' 't' 't' 't' 't' 't' 't' 't']\n",
      "5     f\n",
      "40    t\n",
      "9     f\n",
      "59    f\n",
      "11    f\n",
      "66    f\n",
      "35    t\n",
      "13    f\n",
      "53    f\n",
      "90    t\n",
      "6     f\n",
      "89    t\n",
      "47    f\n",
      "69    t\n",
      "1     f\n",
      "42    t\n",
      "2     f\n",
      "84    t\n",
      "7     f\n",
      "27    t\n",
      "30    t\n",
      "65    f\n",
      "77    t\n",
      "38    t\n",
      "17    f\n",
      "3     f\n",
      "19    f\n",
      "71    t\n",
      "Name: Lie, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(prediction_l)\n",
    "print(actual_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p'\n",
      " 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p' 'p']\n",
      "5     n\n",
      "40    n\n",
      "9     n\n",
      "59    p\n",
      "11    n\n",
      "66    p\n",
      "35    n\n",
      "13    n\n",
      "53    p\n",
      "90    p\n",
      "6     n\n",
      "89    p\n",
      "47    p\n",
      "69    p\n",
      "1     n\n",
      "42    n\n",
      "2     n\n",
      "84    p\n",
      "7     n\n",
      "27    n\n",
      "30    n\n",
      "65    p\n",
      "77    p\n",
      "38    n\n",
      "17    n\n",
      "3     n\n",
      "19    n\n",
      "71    p\n",
      "Name: Sentiment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(prediction_s)\n",
    "print(actual_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pt' 'nf' 'nf' 'nf' 'nf' 'nf' 'pt' 'nf' 'pt' 'nf' 'nf' 'nf' 'nf' 'pt'\n",
      " 'nf' 'pt' 'pt' 'pt' 'pt' 'pt' 'nf' 'pt' 'pt' 'pt' 'nf' 'pt' 'nf' 'nf']\n",
      "67    pf\n",
      "34    nt\n",
      "31    nt\n",
      "70    pt\n",
      "16    nf\n",
      "42    nt\n",
      "52    pf\n",
      "10    nf\n",
      "23    nt\n",
      "85    pt\n",
      "59    pf\n",
      "40    nt\n",
      "41    nt\n",
      "81    pt\n",
      "82    pt\n",
      "47    pf\n",
      "51    pf\n",
      "20    nf\n",
      "50    pf\n",
      "58    pf\n",
      "6     nf\n",
      "1     nf\n",
      "89    pt\n",
      "72    pt\n",
      "3     nf\n",
      "66    pf\n",
      "45    nt\n",
      "36    nt\n",
      "Name: SL, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(prediction_ls)\n",
    "print(actual_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_s = confusion_matrix(actual_l, prediction_l)\n",
    "cm_l = confusion_matrix(actual_s, prediction_s)\n",
    "cm_sl = confusion_matrix(actual_ls, prediction_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  5]\n",
      " [10  4]]\n",
      "\n",
      "[[11  3]\n",
      " [ 4 10]]\n",
      "\n",
      "[[4 0 0 2]\n",
      " [7 0 0 1]\n",
      " [1 0 0 7]\n",
      " [3 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_s)\n",
    "print()\n",
    "print(cm_l)\n",
    "print()\n",
    "print(cm_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nb_model_l.predict_proba(test_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
